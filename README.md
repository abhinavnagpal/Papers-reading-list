# Research-Papers/Articles

## Papers/Articles I need to read

1. Meta-Transfer Learning for Zero-Shot Super-Resolution
2. Learning to Generate Synthetic Data via Compositing
4. https://arxiv.org/pdf/1606.05908.pdf 
5. https://www.countbayesie.com/blog/2015/3/3/6-amazing-trick-with-monte-carlo-simulations
6. An Embarrassingly Simple Approach for Knowledge Distillation
7. NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE
8. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention
9. Effective Approaches to Attention-based Neural Machine Translation
10. Long Short-Term Memory-Networks for Machine Reading
11. Deep contextualized word representations
12. Beyond Accuracy: Behavioral Testing of NLP Models with CheckList
13. Prefix-Tuning: Optimizing Continuous Prompts for Generation
14. Towards Debiasing Sentence Representations
15. POINTER: Constrained Progressive Text Generation via Insertion-based Generative Pre-training
16. Deep Entity Matching with Pre-Trained Language Models
17. Learning advanced mathematical computations from examples
18. A Neuro-Symbolic Method for Solving Differential and Functional Equations
19. Leap-Of-Thought: Teaching Pre-Trained Models to Systematically Reason Over Implicit Knowledge
20. Training Compact Models for Low Resource Entity Tagging using Pre-trained Language Models
21. Global Entity Disambiguation with Pretrained Contextualized Embeddings of Words and Entities
22. Improving Entity Linking by Modeling Latent Entity Type Information
23. Donâ€™t Stop Pretraining: Adapt Language Models to Domains and Tasks

## Papers I Have Read

### Multi-Task Learning
1. Cross Stitch Networks for MTL
2. Mitigating Bias in Gender Age and Ethnicity Classification- a Multi-Task Convolution Neural Network Approach
3. Dynamic Multi-Task Learning with Convolutional Neural Network
4. Multi-Task Convolutional Neural Network for Pose-Invariant Face Recognition
5. Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks
6. Fully-adaptive Feature Sharing in Multi-Task Networks with Applications in Person Attribute Classification

### Programming By Examples
1. Meta-Interpretive Learning of Data Transformation Programs (PBE)
2. Learning Semantic String Transformations from Examples

### Language Generation
1. Train No Evil: Selective Masking for Task-Guided Pre-Training

### Entity Typing
1. Modeling Fine-Grained Entity Types with Box Embeddings

### Symbolic AI
1. Deep Learning for Symbolic Mathematics

### Facial Recognition
1. Affect expression behaviour analysis in the wild using spatio-channel attention and complementary context information

### Others
1. Episode-based Prototype Generating Network for Zero-Shot Learning 
2. Generalized Zero-Shot Learning Via Over-Complete Distribution
3. Learning the Redundancy-free Features for Generalized Zero-Shot Object Recognition
4. Rethinking Zero-shot Video Classification- End-to-end Training for Realistic Applications
5. https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained
6. Attention is all you need
7. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
8. BERTopic: Neural topic modeling with a class-based TF-IDF procedure
